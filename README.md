# Exploring Book Ratings and Prices ‚Äî Web Scraping Project

This project focuses purely on **web scraping** book data from an online bookstore using Python‚Äôs `BeautifulSoup` and `requests` libraries.  
The scraped data includes **book titles, prices, and ratings**, which are saved into a CSV file for future analysis or exploration.
---
## üìò Project Overview

- **Goal:** To collect basic book details (title, price, and rating) from a website.  
- **Scope:** Web scraping only ‚Äî no data analysis or visualization was performed.  
- **Output:** A CSV file named `books_scraped_data.csv` containing structured book data.

##  Dataset Preview

Below is a sample of the dataset used in this project:

![Dataset Screenshot](scraped%20data%20csv.png)
The dataset contains the following columns:
- **Title** ‚Äì Name of the book
- **Price** ‚Äì Price of the book
- **Rating** ‚Äì Star rating of the book


---

## üß∞ Tools and Libraries Used

- **Python 3.x**
- **requests** ‚Äì To send HTTP requests and fetch web pages.
- **BeautifulSoup (bs4)** ‚Äì To parse HTML and extract specific elements.
- **csv / pandas** ‚Äì To store the scraped data into a CSV file.
- **Jupyter Notebook** ‚Äì Used to run and document the scraping process.


---

##  Project Workflow
1. Data scraping
#
---



##  Project Structure

---

## ‚öôÔ∏è How the Scraper Works

1. Sends a GET request to the website‚Äôs book listing pages using `requests`.  
2. Parses the HTML response using `BeautifulSoup`.  
3. Extracts:
   - **Title** ‚Äì The book‚Äôs name.
   - **Price** ‚Äì The listed price (including currency symbol).
   - **Rating** ‚Äì The star rating (e.g., One, Two, Three, etc.).  
4. Stores each record in a list of dictionaries.  
5. Writes the final data into a CSV file named `books_scraped_data.csv`.

---

## ‚ñ∂Ô∏è How to Run

1. **Clone the repository**
   ```bash
   git clone https://github.com/HazoTheAnalyst/Exploring-Book-Ratings-and-Prices.git
   cd Exploring-Book-Ratings-and-Prices

